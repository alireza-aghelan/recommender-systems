{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import files\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "PENwBcez68T8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!pip install --upgrade gdown\n",
        "!pip install patool\n",
        "import patoolib\n",
        "\n",
        "os.mkdir('unzipped_folder')\n",
        "\n",
        "!gdown \"https://drive.google.com/u/0/uc?id=1mipJf49ZvqD3CArtutXNOJriqdtb9tAH&export=download\"\n",
        "\n",
        "patoolib.extract_archive(\"/content/dataset.zip\", outdir=\"/content/unzipped_folder\")\n",
        "\n",
        "ratings = pd.read_csv(\"/content/unzipped_folder/dataset/rating.csv\")\n",
        "animes = pd.read_csv(\"/content/unzipped_folder/dataset/anime.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_-6nPag7QG2",
        "outputId": "03983f15-3ed7-49f0-8a9a-a85d9a650ddf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "Successfully installed gdown-4.7.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n",
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/u/0/uc?id=1mipJf49ZvqD3CArtutXNOJriqdtb9tAH&export=download\n",
            "From (redirected): https://drive.google.com/uc?id=1mipJf49ZvqD3CArtutXNOJriqdtb9tAH&export=download&confirm=t&uuid=adf58e69-93f4-43f0-b2bc-4f28fc3632c3\n",
            "To: /content/dataset.zip\n",
            "100% 26.3M/26.3M [00:00<00:00, 139MB/s]\n",
            "patool: Extracting /content/dataset.zip ...\n",
            "patool: running /usr/bin/7z x -o/content/unzipped_folder -- /content/dataset.zip\n",
            "patool: ... /content/dataset.zip extracted to `/content/unzipped_folder'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "N = len(animes['name'])\n",
        "id_dic = dict(zip(list(range(N)), (animes[\"anime_id\"])))\n",
        "\n",
        "def clean_data(x):\n",
        "\n",
        "    if isinstance(x, list):\n",
        "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
        "    else:\n",
        "        if isinstance(x, str):\n",
        "            return str.lower(x.replace(\" \", \"\"))\n",
        "        else:\n",
        "            return ''\n",
        "\n",
        "\n",
        "features = ['name', 'genre', 'type', 'rating']\n",
        "\n",
        "for feature in features:\n",
        "\n",
        "    animes[feature] = animes[feature].apply(clean_data)\n",
        "\n",
        "\n",
        "def create_soup(x):\n",
        "  \n",
        "    return ' ' + x['name'] + ' ' + x['genre'] + ' ' + x['type'] + ' ' + x['rating']\n",
        "\n",
        "\n",
        "animes['soup'] = animes.apply(create_soup, axis=1)\n",
        "\n",
        "count = CountVectorizer(stop_words='english')\n",
        "count_matrix = count.fit_transform(animes['soup'])\n",
        "\n",
        "cosine_sim2 = cosine_similarity(count_matrix, count_matrix)\n",
        "\n",
        "indices = pd.Series(animes.index, index=animes['anime_id']).drop_duplicates()\n",
        "\n",
        "def get_animes(user_id):\n",
        "\n",
        "  select = ratings.loc[ratings['user_id'] == user_id]\n",
        "  sel = select[['anime_id', 'rating']]\n",
        "  sel_sorted = sel.sort_values(by = 'rating', ascending = False)\n",
        "  all_animes = sel_sorted['anime_id'].tolist()\n",
        "  top_animes = all_animes[0:5]\n",
        "\n",
        "  return top_animes , all_animes\n",
        "  \n",
        "\n",
        "def get_recommendations(top_animes, all_animes, cosine_sim=cosine_sim2):\n",
        "\n",
        "  rec_animes = []\n",
        "\n",
        "  for i in top_animes:\n",
        "\n",
        "    idx = indices[i]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:6]\n",
        "\n",
        "    animes_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    for j in animes_indices:\n",
        "\n",
        "      anime_id = id_dic[j]\n",
        "      \n",
        "      if (anime_id not in rec_animes) and (anime_id not in all_animes):\n",
        "        rec_animes.append(anime_id)\n",
        "\n",
        "  return rec_animes\n",
        "\n",
        "\n",
        "animes_2 = pd.read_csv(\"/content/unzipped_folder/dataset/anime.csv\")\n",
        "ids_names = dict(zip(animes_2['anime_id'], animes_2['name']))"
      ],
      "metadata": {
        "id": "ehLkd6tM9Kat"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = int(input(\"Enter user id: \"))\n",
        "\n",
        "top_animes, all_animes = get_animes(user_id)\n",
        "\n",
        "recommended_animes = get_recommendations(top_animes, all_animes, cosine_sim2)[0:10]\n",
        "\n",
        "print(\"\")\n",
        "print(\"Recommended animes:\")\n",
        "print(\"\")\n",
        "\n",
        "for i in recommended_animes:\n",
        "\n",
        " print(ids_names[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrJjct62-utg",
        "outputId": "031965fc-8441-4d23-8e25-dc1c7a5216d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter user id: 3\n",
            "\n",
            "Recommended animes:\n",
            "\n",
            "Diamond no Ace\n",
            "Area no Kishi\n",
            "Teekyuu 3\n",
            "Mousou Dairinin\n",
            "Higurashi no Naku Koro ni Kai\n",
            "Higurashi no Naku Koro ni\n",
            "Death Note Rewrite\n",
            "Mirai Nikki (TV)\n",
            "Pokemon: Pikachu Koori no Daibouken\n",
            "Pokemon: Pikachu no Wanpaku Island\n"
          ]
        }
      ]
    }
  ]
}