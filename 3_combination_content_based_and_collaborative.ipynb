{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3gcV9G6ZuR4"
      },
      "outputs": [],
      "source": [
        "#Section 3\n",
        "#Combination Content-Based Recommendation AND Collaborative Filtering :\n",
        "\n",
        "#start with Content-Based Recommendation AND\n",
        "#Obtain code movies that are related to the user's interest\n",
        "\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "ratings = pd.read_csv(\"/content/sample_data/rating.csv\")\n",
        "\n",
        "metadata = pd.read_csv(\"/content/sample_data/anime.csv\")\n",
        "\n",
        "\n",
        "#Import TfIdfVectorizer from scikit-learn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "#Construct a reverse map of indices and movie id\n",
        "indices = pd.Series(metadata.index, index=metadata['anime_id']).drop_duplicates()\n",
        "\n",
        "\n",
        "# Function to convert all strings to lower case and strip names of spaces\n",
        "def clean_data(x):\n",
        "    if isinstance(x, list):\n",
        "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
        "    else:\n",
        "        #Check if director exists. If not, return empty string\n",
        "        if isinstance(x, str):\n",
        "            return str.lower(x.replace(\" \", \"\"))\n",
        "        else:\n",
        "            return ''\n",
        "\n",
        "# Apply clean_data function to your features.\n",
        "features = ['name', 'genre', 'type', 'rating']\n",
        "\n",
        "for feature in features:\n",
        "    metadata[feature] = metadata[feature].apply(clean_data)\n",
        "\n",
        "\n",
        "def create_soup(x):\n",
        "    return ' ' + x['name'] + ' ' + x['genre'] + ' ' + x['type'] + ' ' + x['rating']\n",
        "\n",
        "# Create a new soup feature\n",
        "metadata['soup'] = metadata.apply(create_soup, axis=1)\n",
        "\n",
        "\n",
        "# Import CountVectorizer and create the count matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer(stop_words='english')\n",
        "count_matrix = count.fit_transform(metadata['soup'])\n",
        "\n",
        "# Compute the Cosine Similarity matrix based on the count_matrix\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "cosine_sim2 = cosine_similarity(count_matrix, count_matrix)\n",
        "\n",
        "\n",
        "# Reset index of your main DataFrame and construct reverse mapping as before\n",
        "metadata = metadata.reset_index()\n",
        "indices = pd.Series(metadata.index, index=metadata['anime_id']).drop_duplicates()\n",
        "indices_na = pd.Series(metadata.index, index=metadata['name']).drop_duplicates()\n",
        "\n",
        "# get top videos that user has watched\n",
        "def get_movies(user_id):\n",
        "\n",
        "  select = ratings.loc[ratings['user_id'] == user_id]\n",
        "  sel = select[['anime_id', 'rating']]\n",
        "  sel_sorted = sel.sort_values(by = 'rating', ascending = False)\n",
        "\n",
        "  sel_mov = sel_sorted['anime_id'].tolist()\n",
        "\n",
        "  all_mov = sel_sorted['anime_id'].tolist()\n",
        "\n",
        "  m_top = sel_mov[0:20]\n",
        "\n",
        "  return m_top , all_mov\n",
        "\n",
        "\n",
        "N = len(metadata['name'])\n",
        "\t\n",
        "name_dic = dict(zip(list(range(N)), (metadata[\"name\"])))\n",
        "id_dic = dict(zip(list(range(N)), (metadata[\"anime_id\"])))\n",
        "\n",
        "\n",
        "# Function that takes in movie title as input and outputs most similar movies\n",
        "def get_recommendations(top_movies, cosine_sim=cosine_sim2):\n",
        "\n",
        "  mov_id = []\n",
        "\n",
        "  for i in top_movies:\n",
        "\n",
        "    # Get the index of the movie that matches the title\n",
        "    idx = indices[i]\n",
        "\n",
        "    # Get the pairwsie similarity scores of all movies with that movie\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "    # Sort the movies based on the similarity scores\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the scores of the most similar movies\n",
        "    sim_scores = sim_scores[1:41]\n",
        "\n",
        "    # Get the movie indices\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    for j in movie_indices:\n",
        "\n",
        "     vid_id = id_dic[j]\n",
        "     mov_id.append(vid_id)\n",
        "\n",
        " # Return the top most similar movies\n",
        "  return mov_id\n",
        "\n",
        "\n",
        "# user_id = 3\n",
        "top_movies , all_mov = get_movies(3)\n",
        "\n",
        "mov_id = get_recommendations(top_movies , cosine_sim2)\n",
        "\n",
        "mov_id = mov_id + all_mov\n",
        "\n",
        "u_mov_id = set(mov_id)\n",
        "\n",
        "#Now we got the code of the movies\n",
        "#that are related to the user's interest\n",
        "\n",
        "print(\"Number of movie codes related to user interest :\")\n",
        "print(len(u_mov_id))\n",
        "print(\"\")\n",
        "\n",
        "#limit rating dataset with this codes (u_mov_id)\n",
        "new_rate = ratings.loc[ratings['anime_id'].isin(u_mov_id)]\n",
        "\n",
        "print(\"dimension of new rating dataset :\")\n",
        "print(new_rate.shape)\n",
        "print(\"dimension of old rating dataset :\")\n",
        "print(ratings.shape)\n",
        "\n",
        "\n",
        "#Now we apply collaborative filtering on new dataset (new_rate)\n",
        "\n",
        "movies = pd.read_csv(\"/content/sample_data/anime.csv\")\n",
        "\n",
        "n_ratings = len(new_rate)\n",
        "n_movies = len(new_rate['anime_id'].unique())\n",
        "n_users = len(new_rate['user_id'].unique())\n",
        "\n",
        "user_freq = new_rate[['user_id', 'anime_id']].groupby('user_id').count().reset_index()\n",
        "user_freq.columns = ['user_id', 'n_ratings']\n",
        "user_freq.head()\n",
        "\n",
        "# create user-item matrix using scipy csr matrix\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "def create_matrix(df):\n",
        "\t\n",
        "\tN = len(df['user_id'].unique())\n",
        "\tM = len(df['anime_id'].unique())\n",
        "\t\n",
        "\t# Map Ids to indices\n",
        "\tuser_mapper = dict(zip(np.unique(df[\"user_id\"]), list(range(N))))\n",
        "\tmovie_mapper = dict(zip(np.unique(df[\"anime_id\"]), list(range(M))))\n",
        "\t\n",
        "\t# Map indices to IDs\n",
        "\tuser_inv_mapper = dict(zip(list(range(N)), np.unique(df[\"user_id\"])))\n",
        "\tmovie_inv_mapper = dict(zip(list(range(M)), np.unique(df[\"anime_id\"])))\n",
        "\t\n",
        "\tuser_index = [user_mapper[i] for i in df['user_id']]\n",
        "\tmovie_index = [movie_mapper[i] for i in df['anime_id']]\n",
        "\n",
        "\tX = csr_matrix((df[\"rating\"], (movie_index, user_index)), shape=(M, N))\n",
        "\t\n",
        "\treturn X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper\n",
        "\n",
        "X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper = create_matrix(new_rate)\n",
        "\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "#Find similar movies using KNN\n",
        "def find_similar_movies(movie_id, X, k, metric='cosine', show_distance=False):\n",
        "      \n",
        "    neighbour_ids = []\n",
        "      \n",
        "    movie_ind = movie_mapper[movie_id]\n",
        "    movie_vec = X[movie_ind]\n",
        "    k+=1\n",
        "    kNN = NearestNeighbors(n_neighbors=k, algorithm=\"brute\", metric=metric)\n",
        "    kNN.fit(X)\n",
        "    movie_vec = movie_vec.reshape(1,-1)\n",
        "    neighbour = kNN.kneighbors(movie_vec, return_distance=show_distance)\n",
        "    for i in range(0,k):\n",
        "        n = neighbour.item(i)\n",
        "        neighbour_ids.append(movie_inv_mapper[n])\n",
        "    neighbour_ids.pop(0)\n",
        "    return neighbour_ids\n",
        "\n",
        "\n",
        "movie_titles = dict(zip(movies['anime_id'], movies['name']))\n",
        "\n",
        "print(\"\")\n",
        "print(\"for user id 3\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"Suggested videos :\")\n",
        "print(\"\")\n",
        "\n",
        "rec_mov = []\n",
        "\n",
        "for i in top_movies:\n",
        "\n",
        " similar_ids = find_similar_movies(i, X, k=4)\n",
        " for j in similar_ids:\n",
        "\t if (j not in rec_mov) and (j not in all_mov):\n",
        "\t\t \t rec_mov.append(j)\n",
        "\n",
        "ten_mov = rec_mov[0:10]\n",
        "\n",
        "for i in ten_mov:\n",
        "\t\n",
        " print(movie_titles[i])\n",
        " print(\"\")\n"
      ]
    }
  ]
}